{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/OutputRecommendation1.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDVD = df.loc[ df['group'] == 'DVD']\n",
    "dfDVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dfDVD.iloc[0]['salesrank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDf = pd.DataFrame(columns=['ASINs', 'TitleSimilarity', 'CategorySimilarity', 'SalesRank', 'CoPurchasedProducts'])\n",
    "newDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(dfDVD.shape[0]/4)):\n",
    "    row = dfDVD.iloc[i][:]\n",
    "    rowASIN = row['ASIN']\n",
    "    cat_i = row['categories'].split(' ')\n",
    "    title_i = row['title'].split(' ')\n",
    "    #copurchasedASIN = row['copurchased'].split(' ')\n",
    "    for coASIN in dfDVD.iloc[i]['copurchased'].split(' '):\n",
    "        cat_jaccard_similarity = 0\n",
    "        title_jaccard_similarity = 0\n",
    "        cat_j_row = dfDVD.loc[ dfDVD['ASIN'] == coASIN ]\n",
    "        cat_j = cat_j_row['categories'].to_string().split(' ')[1:]\n",
    "#         if i<2:\n",
    "#             print(coASIN)\n",
    "#             print(cat_j)\n",
    "        cat_iUcat_j = set(cat_i).union(set(cat_j))\n",
    "        cat_iIcat_j = set(cat_i).intersection(set(cat_j))\n",
    "        if len(cat_iUcat_j)>0:\n",
    "            cat_jaccard_similarity = round( len(cat_iIcat_j)/len(cat_iUcat_j) , 2)\n",
    "        else:\n",
    "            cat_jaccard_similarity = 0\n",
    "        \n",
    "        title_j = cat_j_row['title'].to_string().split(' ')\n",
    "        title_iUtitle_j = set(title_i).union(set(title_j))\n",
    "        title_iItitle_j = set(title_i).intersection(set(title_j))\n",
    "        if len(title_iUtitle_j)>0:\n",
    "            title_jaccard_similarity = round( len(title_iItitle_j)/ len(title_iUtitle_j) , 2)\n",
    "        else:\n",
    "            title_jaccard_similarity = 0\n",
    "        l = int(row['salesrank'])\n",
    "        print(cat_j_row['salesrank'].to_string().split(' ')[0])\n",
    "        try:\n",
    "            r =  int(cat_j_row['salesrank'].to_string().split(' ')[0] )\n",
    "            print(l,r)\n",
    "            SalesRank = max( l, r)\n",
    "            newDf = newDf.append(pd.Series([ rowASIN+' '+coASIN, title_jaccard_similarity, cat_jaccard_similarity, SalesRank, \"Yes\" ], index=newDf.columns ), ignore_index=True)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBook = df.loc[ df['group'] == 'Book' ]\n",
    "dfBook.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(int(dfBook.shape[0]/25))):\n",
    "    bookASIN = dfBook.iloc[i]['ASIN']\n",
    "    dvdASIN = newDf.iloc[i]['ASINs'].split(' ')[0]\n",
    "    cat_i = dfBook.iloc[i]['categories'].split(' ')\n",
    "    title_i = dfBook.iloc[i]['title'].split(' ')\n",
    "    \n",
    "    cat_jaccard_similarity = 0\n",
    "    title_jaccard_similarity = 0\n",
    "    #cat_j_row = dfDVD.loc[ dfDVD['ASIN'] == coASIN ]\n",
    "    cat_j_row = dfBook.iloc[i][:]\n",
    "    cat_j = cat_j_row['categories'].split(' ')[1:]\n",
    "\n",
    "    cat_iUcat_j = set(cat_i).union(set(cat_j))\n",
    "    cat_iIcat_j = set(cat_i).intersection(set(cat_j))\n",
    "    if len(cat_iUcat_j)>0:\n",
    "        cat_jaccard_similarity = round( len(cat_iIcat_j)/len(cat_iUcat_j) , 2)\n",
    "    else:\n",
    "        cat_jaccard_similarity = 0\n",
    "\n",
    "    title_j = cat_j_row['title'].split(' ')\n",
    "    title_iUtitle_j = set(title_i).union(set(title_j))\n",
    "    title_iItitle_j = set(title_i).intersection(set(title_j))\n",
    "    if len(title_iUtitle_j)>0:\n",
    "        title_jaccard_similarity = round( len(title_iItitle_j)/ len(title_iUtitle_j) , 2)\n",
    "    else:\n",
    "        title_jaccard_similarity = 0\n",
    "    l = int(row['salesrank'])\n",
    "    #print(cat_j_row['salesrank'])\n",
    "    try:\n",
    "        r =  int(cat_j_row['salesrank'] )\n",
    "        #print(l,r)\n",
    "        SalesRank = max( l, r)\n",
    "        newDf = newDf.append(pd.Series([ rowASIN+' '+coASIN, title_jaccard_similarity, cat_jaccard_similarity, SalesRank, \"No\" ], index=newDf.columns ), ignore_index=True)\n",
    "    except ValueError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = newDf.pop('CoPurchasedProducts')\n",
    "X = newDf\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = newDf.pop('ASINs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = newDf\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_onehot = Y.copy()\n",
    "Y_onehot = pd.get_dummies(Y_onehot, columns=['CoPurchasedProducts'], prefix ='CoPurchasedProducts')\n",
    "\n",
    "print(Y_onehot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_onehot.pop('CoPurchasedProducts_Yes')\n",
    "Y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# enc = OneHotEncoder(handle_unknown='ignore')\n",
    "# enc.fit_transform(Y)\n",
    "# #Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, Y_onehot, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.head()\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred, normalize=True, sample_weight=None)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model2 = LogisticRegression(tol=0.00001, solver='liblinear', random_state=42, C= 10, warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc2 = accuracy_score(y_test,y_pred, normalize=True)\n",
    "acc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model3 (with CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "model3 = LogisticRegressionCV(Cs=2, tol=0.001, solver='lbfgs', random_state=42, cv=3, n_jobs=-1, max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model3.predict(x_test)\n",
    "acc3 = accuracy_score(y_test,y_pred, normalize=True)\n",
    "acc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To print the CV scores\n",
    "model3.scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf1 = DecisionTreeClassifier(random_state=42, max_depth=2, persort=True, criterion='gini', max_features = 'sqrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1.fit(X_train,y_train)\n",
    "y_pred = clf1.predict(x_test)\n",
    "accuracy_score(y_test,y_pred,normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
